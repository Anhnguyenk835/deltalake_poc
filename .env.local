
# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS=localhost:29092
KAFKA_GROUP_ID=cdc-python-consumer
KAFKA_AUTO_OFFSET_RESET=earliest
KAFKA_ENABLE_AUTO_COMMIT=false


# Delta Lake Configuration
DELTA_LAKE_PATH=./deltalake             # Base path for Delta Lake tables
DELTA_ENABLE_CDC_EVENTS=true            # Enable/disable CDC event logging to delta_lake/cdc_events
DELTA_ENABLE_SNAPSHOTS=true             # Enable/disable snapshots for source tables
DELTA_RETENTION_HOURS=168               # Retention period for Delta Lake data (in hours)   

# Use PySpark instead of delta-rs
DELTA_USE_SPARK=true                    # Set to false to disable
SPARK_MASTER=local[*]                   # Spark master URL (only used if DELTA_USE_SPARK=true)


# Spark Structured Streaming Configuration
SPARK_STREAMING_ENABLED=true            # Enable Spark Structured Streaming mode
SPARK_CHECKPOINT_PATH=./checkpoints     # Checkpoint directory for exactly-once semantics
SPARK_TRIGGER_INTERVAL=10 seconds       # Micro-batch processing interval
SPARK_MAX_OFFSETS_PER_TRIGGER=10000     # Max Kafka records per micro-batch
SPARK_STARTING_OFFSETS=earliest         # Where to start reading (earliest/latest)


# Data Lake PostgreSQL Configuration
DATALAKE_HOST=localhost
DATALAKE_PORT=5434
DATALAKE_DATABASE=datalake_db
DATALAKE_USER=datalake_user
DATALAKE_PASSWORD=datalake_password


# Target PostgreSQL Configuration
TARGET_HOST=localhost
TARGET_PORT=5435
TARGET_DATABASE=target_db
TARGET_USER=target_user
TARGET_PASSWORD=target_password


